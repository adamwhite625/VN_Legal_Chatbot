from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from app.core.clients import get_llm
from app.services.law_agent.state import LawAgentState

def sufficiency_checker_node(state: LawAgentState) -> LawAgentState:
    llm = get_llm()
    print("ğŸ§  [CHECKER]: Äang kiá»ƒm tra Ä‘á»™ Ä‘áº§y Ä‘á»§ cá»§a thÃ´ng tin...")
    
    query = state.standalone_query or state.query
    docs = state.retrieved_docs or []
    chat_history = state.chat_history or ""
    intent = state.intent or ""
    
    # ----------- LOGIC Má»šI: PhÃ¢n biá»‡t MISSING_INFO vs NO_LAW -----------
    
    # 1. Query is vague only if extremely short (â‰¤ 2 words)
    is_query_vague = len(query.split()) <= 2
    
    # 2. Náº¿u intent quÃ¡ chung chung
    is_intent_generic = intent and intent in ["SEARCH_PENAL", "SEARCH_CIVIL"]
    
    # 3. Náº¿u khÃ´ng tÃ¬m tháº¥y vÄƒn báº£n nÃ o
    if not docs:
        # Náº¿u query mÆ¡ há»“ HOáº¶C intent generic â†’ MISSING_INFO (user cáº§n pháº£i cung cáº¥p chi tiáº¿t hÆ¡n)
        if is_query_vague or is_intent_generic:
            print(f"   -> Query mÆ¡ há»“/intent chung chung â†’ MISSING_INFO")
            state.check_status = "MISSING_INFO"
        else:
            # Query cá»¥ thá»ƒ nhÆ°ng khÃ´ng tÃ¬m Ä‘Æ°á»£c â†’ NO_LAW
            print(f"   -> Query cá»¥ thá»ƒ nhÆ°ng khÃ´ng tÃ¬m Ä‘Æ°á»£c â†’ NO_LAW")
            state.check_status = "NO_LAW"
        
        state.node_trace.append("checker")
        return state

    # --- LOGIC Má»šI: Auto-sufficient cho SEARCH_PROCEDURE ---
    is_procedural = state.intent == "SEARCH_PROCEDURE"
    query_words = len(query.split())
    
    if is_procedural and query_words >= 4:
        print(f"   -> Procedural general query ({query_words} words) â†’ SUFFICIENT (auto)")
        state.check_status = "SUFFICIENT"
        state.node_trace.append("checker")
        return state

    # Táº¡o context tá»« vÄƒn báº£n tÃ¬m Ä‘Æ°á»£c
    context_text = "\n\n".join([f"VÄƒn báº£n: {d.law_name}\nNá»™i dung: {d.content}" for d in docs])

    # --- PROMPT ÄÆ¯á»¢C NÃ‚NG Cáº¤P ("KHÃ“ TÃNH" HÆ N) ---
    checker_prompt = PromptTemplate(
        template="""Báº¡n lÃ  má»™t Tháº©m phÃ¡n cáº¥p cao, cá»±c ká»³ ká»¹ tÃ­nh. Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  Ä‘Ã¡nh giÃ¡ xem thÃ´ng tin hiá»‡n táº¡i ÄÃƒ Äá»¦ Ä‘á»ƒ Ä‘Æ°a ra phÃ¡n quyáº¿t (cÃ¢u tráº£ lá»i) chÃ­nh xÃ¡c cho ngÆ°á»i dÃ¹ng hay chÆ°a.

        1. CÃ‚U Há»I Cá»¦A NGÆ¯á»œI DÃ™NG: "{query}"
        
        2. Lá»ŠCH Sá»¬ TRÃ’ CHUYá»†N (Context):
        {chat_history}

        3. VÄ‚N Báº¢N PHÃP LUáº¬T TÃŒM ÄÆ¯á»¢C:
        {context}

        --- TIÃŠU CHÃ ÄÃNH GIÃ (QUAN TRá»ŒNG) ---
        
        TRÆ¯á»œNG Há»¢P 1: MISSING_INFO (Thiáº¿u thÃ´ng tin chi tiáº¿t)
        - Náº¿u vÄƒn báº£n luáº­t quy Ä‘á»‹nh nhiá»u khung hÃ¬nh pháº¡t khÃ¡c nhau dá»±a trÃªn cÃ¡c yáº¿u tá»‘ Ä‘á»‹nh lÆ°á»£ng (VÃ­ dá»¥: giÃ¡ trá»‹ tÃ i sáº£n, tá»· lá»‡ thÆ°Æ¡ng táº­t, cÃ³ tá»• chá»©c hay khÃ´ng...).
        - VÃ€ ngÆ°á»i dÃ¹ng CHÆ¯A cung cáº¥p cÃ¡c con sá»‘/chi tiáº¿t Ä‘Ã³ trong cÃ¢u há»i hoáº·c lá»‹ch sá»­ chat.
        - VÃ­ dá»¥: Há»i "Trá»™m cáº¯p bá»‹ pháº¡t bao nhiÃªu nÄƒm?" -> Luáº­t cÃ³ khung 6 thÃ¡ng-3 nÄƒm, 2-7 nÄƒm, 7-15 nÄƒm tÃ¹y sá»‘ tiá»n -> NgÆ°á»i dÃ¹ng chÆ°a nÃ³i sá»‘ tiá»n -> MISSING_INFO.
        
        TRÆ¯á»œNG Há»¢P 2: SUFFICIENT (Äá»§ thÃ´ng tin)
        - Náº¿u cÃ¢u há»i chá»‰ mang tÃ­nh Ä‘á»‹nh nghÄ©a, khÃ¡i niá»‡m (VD: "Tháº¿ nÃ o lÃ  ly hÃ´n?").
        - HOáº¶C ngÆ°á»i dÃ¹ng ÄÃƒ cung cáº¥p Ä‘á»§ tÃ¬nh tiáº¿t khá»›p vá»›i má»™t khoáº£n cá»¥ thá»ƒ trong luáº­t.
        - HOáº¶C luáº­t chá»‰ cÃ³ 1 má»©c pháº¡t duy nháº¥t khÃ´ng phá»¥ thuá»™c Ä‘iá»u kiá»‡n.
        
        TRÆ¯á»œNG Há»¢P 3: NO_LAW (Sai luáº­t/KhÃ´ng liÃªn quan)
        - VÄƒn báº£n tÃ¬m Ä‘Æ°á»£c hoÃ n toÃ n khÃ´ng liÃªn quan Ä‘áº¿n cÃ¢u há»i.

        --- YÃŠU Cáº¦U Äáº¦U RA (JSON) ---
        Chá»‰ tráº£ vá» JSON duy nháº¥t, khÃ´ng giáº£i thÃ­ch thÃªm:
        {{
            "status": "SUFFICIENT" | "MISSING_INFO" | "NO_LAW",
            "reason": "Giáº£i thÃ­ch ngáº¯n gá»n táº¡i sao (VÃ­ dá»¥: Cáº§n biáº¿t giÃ¡ trá»‹ tÃ i sáº£n Ä‘á»ƒ xÃ¡c Ä‘á»‹nh khung hÃ¬nh pháº¡t)"
        }}
        """,
        input_variables=["query", "chat_history", "context"]
    )

    chain = checker_prompt | llm | JsonOutputParser()

    try:
        result = chain.invoke({
            "query": query,
            "chat_history": chat_history, 
            "context": context_text
        })
        
        status = result.get("status", "NO_LAW")
        reason = result.get("reason", "")
        
        print(f"   -> ÄÃ¡nh giÃ¡: {status} ({reason})")
        state.check_status = status
        state.node_trace.append("checker")
        return state
        
    except Exception as e:
        print(f"âš ï¸ Lá»—i Checker: {e}")
        state.check_status = "SUFFICIENT"
        state.node_trace.append("checker")
        return state