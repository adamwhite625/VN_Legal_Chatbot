from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from app.core.config import llm

def contextualize_node(state):
    """
    Node 0: Vi·∫øt l·∫°i c√¢u h·ªèi d·ª±a tr√™n l·ªãch s·ª≠ (Contextual Rephrasing)
    """
    query = state["query"]
    chat_history = state.get("chat_history", "")

    # N·∫øu kh√¥ng c√≥ l·ªãch s·ª≠ chat, kh√¥ng c·∫ßn vi·∫øt l·∫°i, tr·∫£ v·ªÅ nguy√™n g·ªëc
    if not chat_history:
        return {"standalone_query": query}

    print(f"üîÑ [REPHRASE]: ƒêang vi·∫øt l·∫°i c√¢u h·ªèi: '{query}'...")

    prompt = PromptTemplate(
        template="""Nhi·ªám v·ª•: Vi·∫øt l·∫°i c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng th√†nh m·ªôt c√¢u h·ªèi ƒë·ªôc l·∫≠p, ƒë·∫ßy ƒë·ªß √Ω nghƒ©a ƒë·ªÉ c√¥ng c·ª• t√¨m ki·∫øm c√≥ th·ªÉ hi·ªÉu ƒë∆∞·ª£c, d·ª±a tr√™n l·ªãch s·ª≠ tr√≤ chuy·ªán.
        
        L·ªãch s·ª≠ tr√≤ chuy·ªán:
        {chat_history}
        
        C√¢u h·ªèi m·ªõi c·ªßa ng∆∞·ªùi d√πng: {query}
        
        Y√™u c·∫ßu:
        1. N·∫øu c√¢u h·ªèi m·ªõi ph·ª• thu·ªôc v√†o l·ªãch s·ª≠ (v√≠ d·ª•: "N√≥ b·ªã ph·∫°t bao nhi√™u?", "Th·ªß t·ª•c th·∫ø n√†o?"), h√£y thay th·∫ø c√°c ƒë·∫°i t·ª´ (n√≥, ƒë√≥, ·∫•y...) b·∫±ng danh t·ª´ c·ª• th·ªÉ t·ª´ l·ªãch s·ª≠.
        2. N·∫øu c√¢u h·ªèi m·ªõi ho√†n to√†n kh√¥ng li√™n quan ƒë·∫øn ch·ªß ƒë·ªÅ tr∆∞·ªõc ƒë√≥, h√£y gi·ªØ nguy√™n c√¢u h·ªèi m·ªõi.
        3. CH·ªà TR·∫¢ V·ªÄ C√ÇU H·ªéI ƒê√É VI·∫æT L·∫†I, kh√¥ng gi·∫£i th√≠ch th√™m.
        
        C√¢u h·ªèi vi·∫øt l·∫°i:""",
        input_variables=["chat_history", "query"]
    )

    chain = prompt | llm | StrOutputParser()
    
    try:
        standalone_query = chain.invoke({
            "chat_history": chat_history,
            "query": query
        })
        print(f"   -> K·∫øt qu·∫£: '{standalone_query}'")
        return {"standalone_query": standalone_query}
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói Rephrase: {e}")
        # N·∫øu l·ªói th√¨ d√πng c√¢u h·ªèi g·ªëc
        return {"standalone_query": query}